# Data-wrangling---weratedogs-project
__Project overview and describtion__:
Use Python and its libraries( pandas, NumPy, requests, tweepy, json),to gather data from a variety of sources and in a variety of formats, assess its **quality** and **tidiness**, then clean it(Detect and document at least eight (8) quality issues and two (2) tidiness issues in wrangle_act.ipynb Jupyter Notebook), document wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python (and its libraries) and/or SQL.

WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because "they're good dogs Brent." WeRateDogs has over 8 million followers and has received international media coverage.
__Objective__:

wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. 

__The Data__


1- Enhanced Twitter Archive in CSV format

2- Additional Data via the Twitter API (Tweet JSON txt)

3- Image Predictions File(tsv format):


__Reporting for this Project__:
Create a 300-600 word written report called wrangle_report.pdf or wrangle_report.html that briefly describes your wrangling efforts. This is to be framed as an internal document.

Create a 250-word-minimum written report called act_report.pdf or act_report.html that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example.
